{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: line 0: cd: /libs/box_utils/cython_utils: No such file or directory\n",
      "running build_ext\n",
      "skipping 'bbox.c' Cython extension (up-to-date)\n",
      "skipping 'nms.c' Cython extension (up-to-date)\n"
     ]
    }
   ],
   "source": [
    "!export LC_ALL=de_DE.utf-8\n",
    "!export LANG=de_DE.utf-8\n",
    "\n",
    "!cd $PATH_ROOT/libs/box_utils/cython_utils\n",
    "!python setup.py build_ext --inplace\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd libs/box_utils/cython_utils\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tfplot/figure.py:18: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/dask/dataframe/utils.py:14: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++--++--++--++--++--++--++--++--++--++--++--++--++--++--++--++--++--++--++--++--\n",
      "/Users/zhangxueqian/Desktop\n",
      "WARNING:tensorflow:From /Users/zhangxueqian/Desktop/Tiny-Defect-Detection-for-PCB-master/libs/networks/mobilenet/mobilenet.py:356: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "\n",
    "import os\n",
    "from os.path import join as pjoin\n",
    "import numpy as np\n",
    "from distutils.core import setup\n",
    "from distutils.extension import Extension\n",
    "from Cython.Distutils import build_ext\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import tfplot as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import time\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from libs.configs import cfgs\n",
    "#from libs.networks import build_whole_network2\n",
    "from libs.networks import build_whole_network\n",
    "from data.io.read_tfrecord import next_batch\n",
    "from libs.box_utils import show_box_in_tensor\n",
    "from help_utils import tools\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import libs\n",
    "import help_utils\n",
    "from libs import configs,networks\n",
    "from libs.networks import resnet\n",
    "from libs.networks import mobilenet_v2\n",
    "from libs.box_utils import encode_and_decode\n",
    "from libs.box_utils import boxes_utils\n",
    "from libs.box_utils import anchor_utils\n",
    "from libs.configs import cfgs\n",
    "from libs.losses import losses\n",
    "from libs.box_utils import show_box_in_tensor\n",
    "from libs.detection_oprations.proposal_opr import postprocess_rpn_proposals\n",
    "from libs.detection_oprations.anchor_target_layer_without_boxweight import anchor_target_layer\n",
    "from libs.detection_oprations.proposal_target_layer import proposal_target_layer\n",
    "\n",
    "import tensorflow.contrib.slim as slim\n",
    "from tensorflow.contrib.slim.nets import resnet_v1\n",
    "from tensorflow.contrib.slim.nets import resnet_utils\n",
    "from tensorflow.contrib.slim.python.slim.nets.resnet_v1 import resnet_v1_block\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running build_ext\n",
      "skipping 'bbox.c' Cython extension (up-to-date)\n",
      "skipping 'nms.c' Cython extension (up-to-date)\n",
      "0.3.2\n"
     ]
    }
   ],
   "source": [
    "!python setup.py build_ext --inplace\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/zhangxueqian/Desktop/Tiny-Defect-Detection-for-PCB-master/tools'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"tools\")\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs.networks import build_whole_network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tfplot/figure.py:18: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\n",
      "/anaconda3/lib/python3.6/site-packages/dask/dataframe/utils.py:14: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n",
      "++--++--++--++--++--++--++--++--++--++--++--++--++--++--++--++--++--++--++--++--\n",
      "/Users/zhangxueqian/Desktop/Tiny-Defect-Detection-for-PCB-master\n",
      "WARNING:tensorflow:From /Users/zhangxueqian/Desktop/Tiny-Defect-Detection-for-PCB-master/tools/libs/networks/mobilenet/mobilenet.py:356: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "Called with args:\n",
      "Namespace(GPU='0', data_dir='/Users/zhangxueqian/Desktop/PCB_DATASET/images/Missing_holesample/', save_dir='/Users/zhangxueqian/Desktop/PCBresults/sample/')\n",
      "['/Users/zhangxueqian/Desktop/PCB_DATASET/images/Missing_holesample/01_missing_hole_02.jpg', '/Users/zhangxueqian/Desktop/PCB_DATASET/images/Missing_holesample/01_missing_hole_03.jpg', '/Users/zhangxueqian/Desktop/PCB_DATASET/images/Missing_holesample/01_missing_hole_01.jpg']\n",
      "WARNING:tensorflow:From inference.py:150: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "WARNING:tensorflow:From inference.py:150: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From inference.py:83: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/data/io/image_preprocess.py:55: The name tf.image.resize_bilinear is deprecated. Please use tf.compat.v1.image.resize_bilinear instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/zhangxueqian/Desktop/Tiny-Defect-Detection-for-PCB-master/tools/libs/networks/resnet.py:28: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/zhangxueqian/Desktop/Tiny-Defect-Detection-for-PCB-master/tools/libs/networks/resnet.py:111: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tfplot/ops.py:114: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "we are in Pyramid::-======>>>>\n",
      "['P2', 'P3', 'P4', 'P5', 'P6']\n",
      "base_anchor_size are:  [15, 25, 40, 60, 80]\n",
      "________________________________________\n",
      "WARNING:tensorflow:From /Users/zhangxueqian/Desktop/Tiny-Defect-Detection-for-PCB-master/tools/libs/networks/build_whole_network.py:218: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /Users/zhangxueqian/Desktop/Tiny-Defect-Detection-for-PCB-master/tools/libs/networks/build_whole_network.py:221: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/zhangxueqian/Desktop/Tiny-Defect-Detection-for-PCB-master/tools/libs/networks/build_whole_network.py:137: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /Users/zhangxueqian/Desktop/Tiny-Defect-Detection-for-PCB-master/tools/libs/networks/build_whole_network.py:541: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model restore from : /Users/zhangxueqian/Desktop/Tiny-Defect-Detection-for-PCB-master/output/trained_weights/FPN_Res101_0117_OHEM/pcb_30000model.ckpt\n",
      "2020-03-14 11:57:28.197374: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "restore model\n",
      "/Users/zhangxueqian/Desktop/PCB_DATASET/images/Missing_holesample/01_missing_hole_01.jpg image cost 2.3824079036712646s:[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100%\t3/3"
     ]
    }
   ],
   "source": [
    "!python inference.py --data_dir='/Users/zhangxueqian/Desktop/PCB_DATASET/images/Missing_holesample/' --save_dir='/Users/zhangxueqian/Desktop/PCBresults/sample/' --GPU='0'\n",
    "\n",
    "# def inference(test_dir, inference_save_path):\n",
    "\n",
    "#     test_imgname_list = [os.path.join(test_dir, img_name_batchame) for img_batchname in os.listdir(test_dir)\n",
    "#                                                           if img_name.endswith(('.jpg', '.png', '.jpeg', '.tif', '.tiff'))]\n",
    "\n",
    "#     print(test_imgname_list)\n",
    "\n",
    "#inference('/Users/zhangxueqian/test','~/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "TensorBoard 1.14.0 at http://zhangxueqians-MacBook-Pro.local:6006/ (Press CTRL+C to quit)\n",
      "I0314 12:01:15.528825 123145397035008 _internal.py:113] ::ffff:192.168.1.103 - - [14/Mar/2020 12:01:15] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "I0314 12:01:16.224517 123145418055680 _internal.py:113] ::ffff:192.168.1.103 - - [14/Mar/2020 12:01:16] \"\u001b[37mGET /data/environment HTTP/1.1\u001b[0m\" 200 -\n",
      "I0314 12:01:16.224739 123145397035008 _internal.py:113] ::ffff:192.168.1.103 - - [14/Mar/2020 12:01:16] \"\u001b[37mGET /data/plugins_listing HTTP/1.1\u001b[0m\" 200 -\n",
      "I0314 12:01:16.225894 123145402290176 _internal.py:113] ::ffff:192.168.1.103 - - [14/Mar/2020 12:01:16] \"\u001b[37mGET /data/runs HTTP/1.1\u001b[0m\" 200 -\n",
      "I0314 12:01:16.226963 123145407545344 _internal.py:113] ::ffff:192.168.1.103 - - [14/Mar/2020 12:01:16] \"\u001b[37mGET /data/experiments HTTP/1.1\u001b[0m\" 200 -\n",
      "I0314 12:01:16.264911 123145397035008 _internal.py:113] ::ffff:192.168.1.103 - - [14/Mar/2020 12:01:16] \"\u001b[37mGET /font-roboto/oMMgfZMQthOryQo9n22dcuvvDin1pK8aKteLpeZ5c0A.woff2 HTTP/1.1\u001b[0m\" 200 -\n",
      "I0314 12:01:16.334794 123145397035008 _internal.py:113] ::ffff:192.168.1.103 - - [14/Mar/2020 12:01:16] \"\u001b[37mGET /font-roboto/RxZJdnzeo3R5zSexge8UUZBw1xU1rKptJj_0jans920.woff2 HTTP/1.1\u001b[0m\" 200 -\n",
      "I0314 12:01:16.506454 123145412800512 _internal.py:113] ::ffff:192.168.1.103 - - [14/Mar/2020 12:01:16] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
      "I0314 12:01:16.540080 123145397035008 _internal.py:113] ::ffff:192.168.1.103 - - [14/Mar/2020 12:01:16] \"\u001b[37mGET /data/plugin/graphs/info HTTP/1.1\u001b[0m\" 200 -\n",
      "I0314 12:01:16.685054 123145397035008 _internal.py:113] ::ffff:192.168.1.103 - - [14/Mar/2020 12:01:16] \"\u001b[37mGET /data/plugin/graphs/graph?run=.&conceptual=false HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir /Users/zhangxueqian/Desktop/Tiny-Defect-Detection-for-PCB-master/tools/logs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inference('/Users/zhangxueqian/Desktop/PCB_DATASET/images/Missing_hole/','~/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs.networks import build_whole_network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import tfplot as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import time\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from libs.configs import cfgs\n",
    "#from libs.networks import build_whole_network2\n",
    "from libs.networks import build_whole_network\n",
    "from data.io.read_tfrecord import next_batch\n",
    "from libs.box_utils import show_box_in_tensor\n",
    "from help_utils import tools\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import libs\n",
    "import help_utils\n",
    "from libs import configs,networks\n",
    "from libs.networks import resnet\n",
    "from libs.networks import mobilenet_v2\n",
    "from libs.box_utils import encode_and_decode\n",
    "from libs.box_utils import boxes_utils\n",
    "from libs.box_utils import anchor_utils\n",
    "from libs.configs import cfgs\n",
    "from libs.losses import losses\n",
    "from libs.box_utils import show_box_in_tensor\n",
    "from libs.detection_oprations.proposal_opr import postprocess_rpn_proposals\n",
    "from libs.detection_oprations.anchor_target_layer_without_boxweight import anchor_target_layer\n",
    "from libs.detection_oprations.proposal_target_layer import proposal_target_layer\n",
    "\n",
    "import tensorflow.contrib.slim as slim\n",
    "from tensorflow.contrib.slim.nets import resnet_v1\n",
    "from tensorflow.contrib.slim.nets import resnet_utils\n",
    "from tensorflow.contrib.slim.python.slim.nets.resnet_v1 import resnet_v1_block\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--data_dir DATA_DIR] [--save_dir SAVE_DIR]\n",
      "                             [--GPU GPU]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /Users/zhangxueqian/Library/Jupyter/runtime/kernel-22a4339a-b011-4f45-a902-d92cb7a1eb94.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2969: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import os, sys\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import cv2\n",
    "import argparse\n",
    "import numpy as np\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from data.io.image_preprocess import short_side_resize_for_inference_data\n",
    "from libs.configs import cfgs\n",
    "from libs.networks import build_whole_network\n",
    "from libs.box_utils import draw_box_in_img\n",
    "from help_utils import tools\n",
    "\n",
    "\n",
    "def detect(det_net, inference_save_path, real_test_imgname_list):\n",
    "\n",
    "    # 1. preprocess img\n",
    "    img_plac = tf.placeholder(dtype=tf.uint8, shape=[None, None, 3])  # is RGB. not GBR\n",
    "    img_batch = tf.cast(img_plac, tf.float32)\n",
    "    img_batch = short_side_resize_for_inference_data(img_tensor=img_batch,\n",
    "                                                     target_shortside_len=cfgs.IMG_SHORT_SIDE_LEN,\n",
    "                                                     length_limitation=cfgs.IMG_MAX_LENGTH)\n",
    "    img_batch = img_batch - tf.constant(cfgs.PIXEL_MEAN)\n",
    "    img_batch = tf.expand_dims(img_batch, axis=0) # [1, None, None, 3]\n",
    "\n",
    "    detection_boxes, detection_scores, detection_category = det_net.build_whole_detection_network(\n",
    "        input_img_batch=img_batch,\n",
    "        gtboxes_batch=None)\n",
    "\n",
    "    init_op = tf.group(\n",
    "        tf.global_variables_initializer(),\n",
    "        tf.local_variables_initializer()\n",
    "    )\n",
    "\n",
    "    restorer, restore_ckpt = det_net.get_restorer()\n",
    "\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "\n",
    "    with tf.Session(config=config) as sess:\n",
    "        sess.run(init_op)\n",
    "        if not restorer is None:\n",
    "            restorer.restore(sess, restore_ckpt)\n",
    "            print('restore model')\n",
    "\n",
    "        for i, a_img_name in enumerate(real_test_imgname_list):\n",
    "\n",
    "            raw_img = cv2.imread(a_img_name)\n",
    "            start = time.time()\n",
    "            resized_img, detected_boxes, detected_scores, detected_categories = \\\n",
    "                sess.run(\n",
    "                    [img_batch, detection_boxes, detection_scores, detection_category],\n",
    "                    feed_dict={img_plac: raw_img[:, :, ::-1]}  # cv is BGR. But need RGB\n",
    "                )\n",
    "            end = time.time()\n",
    "            # print(\"{} cost time : {} \".format(img_name, (end - start)))\n",
    "\n",
    "            show_indices = detected_scores >= cfgs.SHOW_SCORE_THRSHOLD\n",
    "            show_scores = detected_scores[show_indices]\n",
    "            show_boxes = detected_boxes[show_indices]\n",
    "            show_categories = detected_categories[show_indices]\n",
    "            final_detections = draw_box_in_img.draw_boxes_with_label_and_scores(np.squeeze(resized_img, 0),\n",
    "                                                                                boxes=show_boxes,\n",
    "                                                                                labels=show_categories,\n",
    "                                                                                scores=show_scores)\n",
    "            nake_name = a_img_name.split('/')[-1]\n",
    "            # print (inference_save_path + '/' + nake_name)\n",
    "            cv2.imwrite(inference_save_path + '/' + nake_name,\n",
    "                        final_detections[:, :, ::-1])\n",
    "\n",
    "            tools.view_bar('{} image cost {}s'.format(a_img_name, (end - start)), i + 1, len(real_test_imgname_list))\n",
    "\n",
    "\n",
    "def inference(test_dir, inference_save_path):\n",
    "\n",
    "    test_imgname_list = [os.path.join(test_dir, img_name) for img_name in os.listdir(test_dir)\n",
    "                                                          if img_name.endswith(('.jpg', '.png', '.jpeg', '.tif', '.tiff'))]\n",
    "    assert len(test_imgname_list) != 0, 'test_dir has no imgs there.' \\\n",
    "                                        ' Note that, we only support img format of (.jpg, .png, and .tiff) '\n",
    "\n",
    "    faster_rcnn = build_whole_network.DetectionNetwork(base_network_name=cfgs.NET_NAME,\n",
    "                                                       is_training=False)\n",
    "    detect(det_net=faster_rcnn, inference_save_path=inference_save_path, real_test_imgname_list=test_imgname_list)\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    \"\"\"\n",
    "    Parse input arguments\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser(description='TestImgs...U need provide the test dir')\n",
    "\n",
    "    parser.add_argument('--data_dir', dest='data_dir',\n",
    "                        help='data path',\n",
    "                        default='demos', type=str)\n",
    "    parser.add_argument('--save_dir', dest='save_dir',\n",
    "                        help='demo imgs to save',\n",
    "                        default='inference_results', type=str)\n",
    "    parser.add_argument('--GPU', dest='GPU',\n",
    "                        help='gpu id ',\n",
    "                        default='0', type=str)\n",
    "\n",
    "    if len(sys.argv) == 1:\n",
    "        parser.print_help()\n",
    "        sys.exit(1)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    return args\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    args = parse_args()\n",
    "    print('Called with args:')\n",
    "    print(args)\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.GPU\n",
    "    inference(args.data_dir,\n",
    "              inference_save_path=args.save_dir)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:\n",
      "UnicodeDecodeError while processing traceback.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfrecord path is --> /Users/zhangxueqian/Desktop/Tiny-Defect-Detection-for-PCB-master/data/tfrecord/pcb_train*\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode bytes in position 1465-1466: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "faster_rcnn = build_whole_network.DetectionNetwork(base_network_name=cfgs.NET_NAME,\n",
    "                                                       is_training=True)\n",
    "with tf.name_scope('get_batch'):\n",
    "        img_name_batch, img_batch, gtboxes_and_label_batch, num_objects_batch = \\\n",
    "            next_batch(dataset_name=cfgs.DATASET_NAME,  # 'pascal', 'coco'\n",
    "                       batch_size=cfgs.BATCH_SIZE,\n",
    "                       shortside_len=cfgs.IMG_SHORT_SIDE_LEN,\n",
    "                       is_training=True)\n",
    "        gtboxes_and_label = tf.reshape(gtboxes_and_label_batch, [-1, 5])\n",
    "\n",
    "biases_regularizer = tf.no_regularizer\n",
    "weights_regularizer = tf.contrib.layers.l2_regularizer(cfgs.WEIGHT_DECAY)\n",
    "# list as many types of layers as possible, even if they are not used now\n",
    " # list as many types of layers as possible, even if they are not used now\n",
    "with slim.arg_scope([slim.conv2d, slim.conv2d_in_plane, \\\n",
    "                         slim.conv2d_transpose, slim.separable_conv2d, slim.fully_connected],\n",
    "                        weights_regularizer=weights_regularizer,\n",
    "                        biases_regularizer=biases_regularizer,\n",
    "                        biases_initializer=tf.constant_initializer(0.0)):\n",
    "    final_bbox, final_scores, final_category, loss_dict = faster_rcnn.build_whole_detection_network(\n",
    "            input_img_batch=img_batch,\n",
    "            gtboxes_batch=gtboxes_and_label)\n",
    " # ----------------------------------------------------------------------------------------------------build loss\n",
    "weight_decay_loss = tf.add_n(slim.losses.get_regularization_losses())\n",
    "rpn_location_loss = loss_dict['rpn_loc_loss']\n",
    "rpn_cls_loss = loss_dict['rpn_cls_loss']\n",
    "rpn_total_loss = rpn_location_loss + rpn_cls_loss\n",
    "\n",
    "fastrcnn_cls_loss = loss_dict['fastrcnn_cls_loss']\n",
    "fastrcnn_loc_loss = loss_dict['fastrcnn_loc_loss']\n",
    "fastrcnn_total_loss = fastrcnn_cls_loss + fastrcnn_loc_loss\n",
    "\n",
    "total_loss = rpn_total_loss + fastrcnn_total_loss + weight_decay_loss\n",
    "    # ____________________________________________________________________________________________________build loss\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_decay_loss = tf.add_n(slim.losses.get_regularization_losses())\n",
    "rpn_location_loss = loss_dict['rpn_loc_loss']\n",
    "rpn_cls_loss = loss_dict['rpn_cls_loss']\n",
    "rpn_total_loss = rpn_location_loss + rpn_cls_loss\n",
    "\n",
    "fastrcnn_cls_loss = loss_dict['fastrcnn_cls_loss']\n",
    "fastrcnn_loc_loss = loss_dict['fastrcnn_loc_loss']\n",
    "fastrcnn_total_loss = fastrcnn_cls_loss + fastrcnn_loc_loss\n",
    "\n",
    "total_loss = rpn_total_loss + fastrcnn_total_loss + weight_decay_loss\n",
    "    # ____________________________________________________________________________________________________build loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-15-72fb0f468268>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-72fb0f468268>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    tf.summary.scalar('RPN_LOSS/cls_loss', rpn_cls_loss)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------------------------------add summary\n",
    "\n",
    "tf.summary.scalar('RPN_LOSS/cls_loss', rpn_cls_loss)\n",
    "tf.summary.scalar('RPN_LOSS/location_loss', rpn_location_loss)\n",
    "tf.summary.scalar('RPN_LOSS/rpn_total_loss', rpn_total_loss)\n",
    "\n",
    "tf.summary.scalar('FAST_LOSS/fastrcnn_cls_loss', fastrcnn_cls_loss)\n",
    "tf.summary.scalar('FAST_LOSS/fastrcnn_location_loss', fastrcnn_loc_loss)\n",
    "tf.summary.scalar('FAST_LOSS/fastrcnn_total_loss', fastrcnn_total_loss)\n",
    "\n",
    "tf.summary.scalar('LOSS/total_loss', total_loss)\n",
    "tf.summary.scalar('LOSS/regular_weights', weight_decay_loss)\n",
    "\n",
    "gtboxes_in_img = show_box_in_tensor.draw_boxes_with_categories(img_batch=img_batch,\n",
    "                                                                   boxes=gtboxes_and_label[:, :-1],\n",
    "                                                                   labels=gtboxes_and_label[:, -1])\n",
    "if cfgs.ADD_BOX_IN_TENSORBOARD:\n",
    "    detections_in_img = show_box_in_tensor.draw_boxes_with_categories_and_scores(img_batch=img_batch,\n",
    "                                                                                     boxes=final_bbox,\n",
    "                                                                                     labels=final_category,\n",
    "                                                                                     scores=final_scores)\n",
    "tf.summary.image('Compare/final_detection', detections_in_img)\n",
    "tf.summary.image('Compare/gtboxes', gtboxes_in_img)\n",
    "\n",
    "    # ___________________________________________________________________________________________________add summary\n",
    "\n",
    "global_step = slim.get_or_create_global_step()\n",
    "lr = tf.train.piecewise_constant(global_step,\n",
    "                                     boundaries=[np.int64(cfgs.DECAY_STEP[0]), np.int64(cfgs.DECAY_STEP[1])],\n",
    "                                     values=[cfgs.LR, cfgs.LR / 10., cfgs.LR / 100.])\n",
    "tf.summary.scalar('lr', lr)\n",
    "optimizer = tf.train.MomentumOptimizer(lr, momentum=cfgs.MOMENTUM)\n",
    "    # optimizer = tf.train.AdamOptimizer(lr)\n",
    "\n",
    "    # ---------------------------------------------------------------------------------------------compute gradients\n",
    "gradients = faster_rcnn.get_gradients(optimizer, total_loss)\n",
    "\n",
    "    # enlarge_gradients for bias\n",
    "if cfgs.MUTILPY_BIAS_GRADIENT:\n",
    "    gradients = faster_rcnn.enlarge_gradients_for_bias(gradients)\n",
    "\n",
    "if cfgs.GRADIENT_CLIPPING_BY_NORM:\n",
    "    with tf.name_scope('clip_gradients_YJR'):\n",
    "        gradients = slim.learning.clip_gradient_norms(gradients,\n",
    "                                                          cfgs.GRADIENT_CLIPPING_BY_NORM)\n",
    "    # _____________________________________________________________________________________________compute gradients\n",
    "\n",
    " # train_op\n",
    "train_op = optimizer.apply_gradients(grads_and_vars=gradients,\n",
    "                                         global_step=global_step)\n",
    "summary_op = tf.summary.merge_all()\n",
    "init_op = tf.group(\n",
    "        tf.global_variables_initializer(),\n",
    "        tf.local_variables_initializer()\n",
    "    )\n",
    "\n",
    "restorer, restore_ckpt = faster_rcnn.get_restorer()\n",
    "saver = tf.train.Saver(max_to_keep=30)\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "compute_time = 0\n",
    "compute_imgnum = 0\n",
    "\n",
    "    with tf.Session(config=config) as sess:\n",
    "        sess.run(init_op)\n",
    "        if not restorer is None:\n",
    "            restorer.restore(sess, restore_ckpt)\n",
    "            print('restore model')\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(sess, coord)\n",
    "\n",
    "        summary_path = os.path.join(cfgs.SUMMARY_PATH, cfgs.VERSION)\n",
    "        tools.mkdir(summary_path)\n",
    "        summary_writer = tf.summary.FileWriter(summary_path, graph=sess.graph)\n",
    "        training_time = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time()))\n",
    "\n",
    "        for step in range(cfgs.MAX_ITERATION):\n",
    "            training_time1 = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time()))\n",
    "            if step % cfgs.SHOW_TRAIN_INFO_INTE != 0 and step % cfgs.SMRY_ITER != 0:\n",
    "                _, global_stepnp = sess.run([train_op, global_step])\n",
    "\n",
    "            else:\n",
    "                if step % cfgs.SHOW_TRAIN_INFO_INTE == 0 and step % cfgs.SMRY_ITER != 0:\n",
    "                    start = time.time()\n",
    "\n",
    "                    _, global_stepnp, img_name, rpnLocLoss, rpnClsLoss, rpnTotalLoss, \\\n",
    "                    fastrcnnLocLoss, fastrcnnClsLoss, fastrcnnTotalLoss, totalLoss = \\\n",
    "                        sess.run(\n",
    "                            [train_op, global_step, img_name_batch, rpn_location_loss, rpn_cls_loss, rpn_total_loss,\n",
    "                             fastrcnn_loc_loss, fastrcnn_cls_loss, fastrcnn_total_loss, total_loss])\n",
    "\n",
    "                    end = time.time()\n",
    "                    compute_time = compute_time + (end - start)\n",
    "                    compute_imgnum = compute_imgnum + 1\n",
    "                    print(\"\"\" {}: step{}    image_name:{} |\\t\n",
    "                              rpn_loc_loss:{} |\\t rpn_cla_loss:{} |\\t rpn_total_loss:{} |\n",
    "                              fast_rcnn_loc_loss:{} |\\t fast_rcnn_cla_loss:{} |\\t fast_rcnn_total_loss:{} |\n",
    "                              total_loss:{} |\\t per_cost_time:{}s\"\"\" \\\n",
    "                          .format(training_time1, global_stepnp, str(img_name[0]), rpnLocLoss, rpnClsLoss,\n",
    "                                  rpnTotalLoss, fastrcnnLocLoss, fastrcnnClsLoss, fastrcnnTotalLoss, totalLoss,\n",
    "                                  (end - start)))\n",
    "                else:\n",
    "                    if step % cfgs.SMRY_ITER == 0:\n",
    "                        _, global_stepnp, summary_str = sess.run([train_op, global_step, summary_op])\n",
    "                        summary_writer.add_summary(summary_str, global_stepnp)\n",
    "                        summary_writer.flush()\n",
    "\n",
    "            if (step > 0 and step % cfgs.SAVE_WEIGHTS_INTE == 0) or (step == cfgs.MAX_ITERATION - 1):\n",
    "\n",
    "                save_dir = os.path.join(cfgs.TRAINED_CKPT, cfgs.VERSION)\n",
    "                if not os.path.exists(save_dir):\n",
    "                    os.mkdir(save_dir)\n",
    "\n",
    "                #save_ckpt = os.path.join(save_dir, 'voc_' + str(global_stepnp) + 'model.ckpt')\n",
    "                save_ckpt = os.path.join(save_dir, 'pcb_' + str(global_stepnp) + 'model.ckpt')\n",
    "                saver.save(sess, save_ckpt)\n",
    "                print(' weights had been saved')\n",
    "        print('average_training_time_per_image is' + str(compute_time / compute_imgnum))\n",
    "        print('traning start time is ' + training_time)\n",
    "        end_training_time = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time()))\n",
    "        print('traning end time is ' + end_training_time)\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:\n",
      "UnicodeDecodeError while processing traceback.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfrecord path is --> /Users/zhangxueqian/Desktop/Tiny-Defect-Detection-for-PCB-master/data/tfrecord/pcb_train*\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode bytes in position 1465-1466: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def train():\n",
    "\n",
    "    faster_rcnn = build_whole_network.DetectionNetwork(base_network_name=cfgs.NET_NAME,\n",
    "                                                       is_training=True)\n",
    "\n",
    "    with tf.name_scope('get_batch'):\n",
    "        img_name_batch, img_batch, gtboxes_and_label_batch, num_objects_batch = \\\n",
    "            next_batch(dataset_name=cfgs.DATASET_NAME,  # 'pascal', 'coco'\n",
    "                       batch_size=cfgs.BATCH_SIZE,\n",
    "                       shortside_len=cfgs.IMG_SHORT_SIDE_LEN,\n",
    "                       is_training=True)\n",
    "        gtboxes_and_label = tf.reshape(gtboxes_and_label_batch, [-1, 5])\n",
    "\n",
    "    biases_regularizer = tf.no_regularizer\n",
    "    weights_regularizer = tf.contrib.layers.l2_regularizer(cfgs.WEIGHT_DECAY)\n",
    "\n",
    "    # list as many types of layers as possible, even if they are not used now\n",
    "    with slim.arg_scope([slim.conv2d, slim.conv2d_in_plane, \\\n",
    "                         slim.conv2d_transpose, slim.separable_conv2d, slim.fully_connected],\n",
    "                        weights_regularizer=weights_regularizer,\n",
    "                        biases_regularizer=biases_regularizer,\n",
    "                        biases_initializer=tf.constant_initializer(0.0)):\n",
    "        final_bbox, final_scores, final_category, loss_dict = faster_rcnn.build_whole_detection_network(\n",
    "            input_img_batch=img_batch,\n",
    "            gtboxes_batch=gtboxes_and_label)\n",
    "\n",
    "    # ----------------------------------------------------------------------------------------------------build loss\n",
    "    weight_decay_loss = tf.add_n(slim.losses.get_regularization_losses())\n",
    "    rpn_location_loss = loss_dict['rpn_loc_loss']\n",
    "    rpn_cls_loss = loss_dict['rpn_cls_loss']\n",
    "    rpn_total_loss = rpn_location_loss + rpn_cls_loss\n",
    "\n",
    "    fastrcnn_cls_loss = loss_dict['fastrcnn_cls_loss']\n",
    "    fastrcnn_loc_loss = loss_dict['fastrcnn_loc_loss']\n",
    "    fastrcnn_total_loss = fastrcnn_cls_loss + fastrcnn_loc_loss\n",
    "\n",
    "    total_loss = rpn_total_loss + fastrcnn_total_loss + weight_decay_loss\n",
    "    # ____________________________________________________________________________________________________build loss\n",
    "\n",
    "\n",
    "    # ---------------------------------------------------------------------------------------------------add summary\n",
    "\n",
    "    tf.summary.scalar('RPN_LOSS/cls_loss', rpn_cls_loss)\n",
    "    tf.summary.scalar('RPN_LOSS/location_loss', rpn_location_loss)\n",
    "    tf.summary.scalar('RPN_LOSS/rpn_total_loss', rpn_total_loss)\n",
    "\n",
    "    tf.summary.scalar('FAST_LOSS/fastrcnn_cls_loss', fastrcnn_cls_loss)\n",
    "    tf.summary.scalar('FAST_LOSS/fastrcnn_location_loss', fastrcnn_loc_loss)\n",
    "    tf.summary.scalar('FAST_LOSS/fastrcnn_total_loss', fastrcnn_total_loss)\n",
    "\n",
    "    tf.summary.scalar('LOSS/total_loss', total_loss)\n",
    "    tf.summary.scalar('LOSS/regular_weights', weight_decay_loss)\n",
    "\n",
    "    gtboxes_in_img = show_box_in_tensor.draw_boxes_with_categories(img_batch=img_batch,\n",
    "                                                                   boxes=gtboxes_and_label[:, :-1],\n",
    "                                                                   labels=gtboxes_and_label[:, -1])\n",
    "    if cfgs.ADD_BOX_IN_TENSORBOARD:\n",
    "        detections_in_img = show_box_in_tensor.draw_boxes_with_categories_and_scores(img_batch=img_batch,\n",
    "                                                                                     boxes=final_bbox,\n",
    "                                                                                     labels=final_category,\n",
    "                                                                                     scores=final_scores)\n",
    "        tf.summary.image('Compare/final_detection', detections_in_img)\n",
    "    tf.summary.image('Compare/gtboxes', gtboxes_in_img)\n",
    "\n",
    "    # ___________________________________________________________________________________________________add summary\n",
    "\n",
    "    global_step = slim.get_or_create_global_step()\n",
    "    lr = tf.train.piecewise_constant(global_step,\n",
    "                                     boundaries=[np.int64(cfgs.DECAY_STEP[0]), np.int64(cfgs.DECAY_STEP[1])],\n",
    "                                     values=[cfgs.LR, cfgs.LR / 10., cfgs.LR / 100.])\n",
    "    tf.summary.scalar('lr', lr)\n",
    "    optimizer = tf.train.MomentumOptimizer(lr, momentum=cfgs.MOMENTUM)\n",
    "    # optimizer = tf.train.AdamOptimizer(lr)\n",
    "\n",
    "    # ---------------------------------------------------------------------------------------------compute gradients\n",
    "    gradients = faster_rcnn.get_gradients(optimizer, total_loss)\n",
    "\n",
    "    # enlarge_gradients for bias\n",
    "    if cfgs.MUTILPY_BIAS_GRADIENT:\n",
    "        gradients = faster_rcnn.enlarge_gradients_for_bias(gradients)\n",
    "\n",
    "    if cfgs.GRADIENT_CLIPPING_BY_NORM:\n",
    "        with tf.name_scope('clip_gradients_YJR'):\n",
    "            gradients = slim.learning.clip_gradient_norms(gradients,\n",
    "                                                          cfgs.GRADIENT_CLIPPING_BY_NORM)\n",
    "    # _____________________________________________________________________________________________compute gradients\n",
    "\n",
    " # train_op\n",
    "    train_op = optimizer.apply_gradients(grads_and_vars=gradients,\n",
    "                                         global_step=global_step)\n",
    "    summary_op = tf.summary.merge_all()\n",
    "    init_op = tf.group(\n",
    "        tf.global_variables_initializer(),\n",
    "        tf.local_variables_initializer()\n",
    "    )\n",
    "\n",
    "    restorer, restore_ckpt = faster_rcnn.get_restorer()\n",
    "    saver = tf.train.Saver(max_to_keep=30)\n",
    "\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    compute_time = 0\n",
    "    compute_imgnum = 0\n",
    "\n",
    "    with tf.Session(config=config) as sess:\n",
    "        sess.run(init_op)\n",
    "        if not restorer is None:\n",
    "            restorer.restore(sess, restore_ckpt)\n",
    "            print('restore model')\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(sess, coord)\n",
    "\n",
    "        summary_path = os.path.join(cfgs.SUMMARY_PATH, cfgs.VERSION)\n",
    "        tools.mkdir(summary_path)\n",
    "        summary_writer = tf.summary.FileWriter(summary_path, graph=sess.graph)\n",
    "        training_time = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time()))\n",
    "\n",
    "        for step in range(cfgs.MAX_ITERATION):\n",
    "            training_time1 = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time()))\n",
    "            if step % cfgs.SHOW_TRAIN_INFO_INTE != 0 and step % cfgs.SMRY_ITER != 0:\n",
    "                _, global_stepnp = sess.run([train_op, global_step])\n",
    "\n",
    "            else:\n",
    "                if step % cfgs.SHOW_TRAIN_INFO_INTE == 0 and step % cfgs.SMRY_ITER != 0:\n",
    "                    start = time.time()\n",
    "\n",
    "                    _, global_stepnp, img_name, rpnLocLoss, rpnClsLoss, rpnTotalLoss, \\\n",
    "                    fastrcnnLocLoss, fastrcnnClsLoss, fastrcnnTotalLoss, totalLoss = \\\n",
    "                        sess.run(\n",
    "                            [train_op, global_step, img_name_batch, rpn_location_loss, rpn_cls_loss, rpn_total_loss,\n",
    "                             fastrcnn_loc_loss, fastrcnn_cls_loss, fastrcnn_total_loss, total_loss])\n",
    "\n",
    "                    end = time.time()\n",
    "                    compute_time = compute_time + (end - start)\n",
    "                    compute_imgnum = compute_imgnum + 1\n",
    "                    print(\"\"\" {}: step{}    image_name:{} |\\t\n",
    "                              rpn_loc_loss:{} |\\t rpn_cla_loss:{} |\\t rpn_total_loss:{} |\n",
    "                              fast_rcnn_loc_loss:{} |\\t fast_rcnn_cla_loss:{} |\\t fast_rcnn_total_loss:{} |\n",
    "                              total_loss:{} |\\t per_cost_time:{}s\"\"\" \\\n",
    "                          .format(training_time1, global_stepnp, str(img_name[0]), rpnLocLoss, rpnClsLoss,\n",
    "                                  rpnTotalLoss, fastrcnnLocLoss, fastrcnnClsLoss, fastrcnnTotalLoss, totalLoss,\n",
    "                                  (end - start)))\n",
    "                else:\n",
    "                    if step % cfgs.SMRY_ITER == 0:\n",
    "                        _, global_stepnp, summary_str = sess.run([train_op, global_step, summary_op])\n",
    "                        summary_writer.add_summary(summary_str, global_stepnp)\n",
    "                        summary_writer.flush()\n",
    "\n",
    "            if (step > 0 and step % cfgs.SAVE_WEIGHTS_INTE == 0) or (step == cfgs.MAX_ITERATION - 1):\n",
    "\n",
    "                save_dir = os.path.join(cfgs.TRAINED_CKPT, cfgs.VERSION)\n",
    "                if not os.path.exists(save_dir):\n",
    "                    os.mkdir(save_dir)\n",
    "\n",
    "                #save_ckpt = os.path.join(save_dir, 'voc_' + str(global_stepnp) + 'model.ckpt')\n",
    "                save_ckpt = os.path.join(save_dir, 'pcb_' + str(global_stepnp) + 'model.ckpt')\n",
    "                saver.save(sess, save_ckpt)\n",
    "                print(' weights had been saved')\n",
    "        print('average_training_time_per_image is' + str(compute_time / compute_imgnum))\n",
    "        print('traning start time is ' + training_time)\n",
    "        end_training_time = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time()))\n",
    "        print('traning end time is ' + end_training_time)\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    train()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import os, sys\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import cv2\n",
    "import pickle\n",
    "import numpy as np\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from data.io.image_preprocess import short_side_resize_for_inference_data\n",
    "from libs.configs import cfgs\n",
    "from libs.networks import build_whole_network\n",
    "from libs.val_libs import voc_eval\n",
    "from libs.box_utils import draw_box_in_img\n",
    "import argparse\n",
    "from help_utils import tools\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tfplot/figure.py:18: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\n",
      "/anaconda3/lib/python3.6/site-packages/dask/dataframe/utils.py:14: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n",
      "++--++--++--++--++--++--++--++--++--++--++--++--++--++--++--++--++--++--++--++--\n",
      "/Users/zhangxueqian/Desktop/Tiny-Defect-Detection-for-PCB-master\n",
      "WARNING:tensorflow:From /Users/zhangxueqian/Desktop/Tiny-Defect-Detection-for-PCB-master/tools/libs/networks/mobilenet/mobilenet.py:356: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "----------------------------------------\n",
      "Namespace(GPU='2', eval_imgs='/Users/zhangxueqian/Desktop/PCB_DATASET/images/Missing_hole/', eval_num=100, showbox=False, test_annotation_dir='/Users/zhangxueqian/Desktop/PCBresults/Annotations/--GPU=0')\n",
      "----------------------------------------\n",
      "WARNING:tensorflow:From eval.py:70: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/data/io/image_preprocess.py:55: The name tf.image.resize_bilinear is deprecated. Please use tf.compat.v1.image.resize_bilinear instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/zhangxueqian/Desktop/Tiny-Defect-Detection-for-PCB-master/tools/libs/networks/resnet.py:28: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/zhangxueqian/Desktop/Tiny-Defect-Detection-for-PCB-master/tools/libs/networks/resnet.py:111: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tfplot/ops.py:114: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "we are in Pyramid::-======>>>>\n",
      "['P2', 'P3', 'P4', 'P5', 'P6']\n",
      "base_anchor_size are:  [15, 25, 40, 60, 80]\n",
      "________________________________________\n",
      "WARNING:tensorflow:From /Users/zhangxueqian/Desktop/Tiny-Defect-Detection-for-PCB-master/tools/libs/networks/build_whole_network.py:206: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/zhangxueqian/Desktop/Tiny-Defect-Detection-for-PCB-master/tools/libs/networks/build_whole_network.py:218: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /Users/zhangxueqian/Desktop/Tiny-Defect-Detection-for-PCB-master/tools/libs/networks/build_whole_network.py:221: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/zhangxueqian/Desktop/Tiny-Defect-Detection-for-PCB-master/tools/libs/networks/build_whole_network.py:137: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /Users/zhangxueqian/Desktop/Tiny-Defect-Detection-for-PCB-master/tools/libs/networks/build_whole_network.py:541: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "model restore from : /Users/zhangxueqian/Desktop/Tiny-Defect-Detection-for-PCB-master/output/trained_weights/FPN_Res101_0117_OHEM/pcb_30000model.ckpt\n",
      "2020-03-10 21:20:08.845517: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "restore model\n",
      "12_missing_hole_08.jpg image cost 1.4587640762329102s:[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100%\t115/115\n",
      " average_training_time_per_image is1.9650148080742877\n",
      "Writing missing_hole VOC resutls file\n",
      "Writing mouse_bite VOC resutls file\n",
      "Writing open_circuit VOC resutls file\n",
      "Writing short VOC resutls file\n",
      "Writing spur VOC resutls file\n",
      "Writing spurious_copper VOC resutls file\n",
      "Traceback (most recent call last):\n",
      "  File \"eval.py\", line 228, in <module>\n",
      "    showbox=args.showbox)\n",
      "  File \"eval.py\", line 190, in eval\n",
      "    test_imgid_list=real_test_imgname_list)\n",
      "  File \"/Users/zhangxueqian/Desktop/Tiny-Defect-Detection-for-PCB-master/tools/libs/val_libs/voc_eval.py\", line 266, in voc_evaluate_detections\n",
      "    do_python_eval(test_imgid_list, test_annotation_path=test_annotation_path)\n",
      "  File \"/Users/zhangxueqian/Desktop/Tiny-Defect-Detection-for-PCB-master/tools/libs/val_libs/voc_eval.py\", line 236, in do_python_eval\n",
      "    annopath=test_annotation_path)\n",
      "  File \"/Users/zhangxueqian/Desktop/Tiny-Defect-Detection-for-PCB-master/tools/libs/val_libs/voc_eval.py\", line 130, in voc_eval\n",
      "    recs[imagename] = parse_rec(os.path.join(annopath, imagename+'.xml'))\n",
      "  File \"/Users/zhangxueqian/Desktop/Tiny-Defect-Detection-for-PCB-master/tools/libs/val_libs/voc_eval.py\", line 58, in parse_rec\n",
      "    tree = ET.parse(filename)\n",
      "  File \"/anaconda3/lib/python3.6/xml/etree/ElementTree.py\", line 1196, in parse\n",
      "    tree.parse(source, parser)\n",
      "  File \"/anaconda3/lib/python3.6/xml/etree/ElementTree.py\", line 586, in parse\n",
      "    source = open(source, \"rb\")\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/Users/zhangxueqian/Desktop/PCBresults/Annotations/--GPU=0/08_missing_hole_07.xml'\n"
     ]
    }
   ],
   "source": [
    "!python eval.py --eval_imgs='/Users/zhangxueqian/Desktop/PCB_DATASET/images/Missing_hole/' --annotation_dir='/Users/zhangxueqian/Desktop/PCB_DATASET/Annotations/'--GPU='0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
